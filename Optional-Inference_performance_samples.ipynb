{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get system environment info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "env_dist = os.environ\n",
    "for key in env_dist:\n",
    "    print(key + ':' + env_dist[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get system path info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Lab1: inference sample code using sync API (for iv3/mn/vgg16 model)\n",
    "### *arg_model_xml* : the model xml (generated from mo.py)\n",
    "### *arg_model_bin* : the model bin (generated from mo.py)\n",
    "### *arg_device* : the device to run inferences, can be one of CPU/GPU/MYRIAD\n",
    "### *arg_image_number* : total infer requests to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# sync api demo\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "\n",
    "#mobilenet\n",
    "arg_model_xml=\"./tf_model/mn/FP16/all_layers.mn.xml\"\n",
    "arg_model_bin=\"./tf_model/mn/FP16/all_layers.mn.bin\"\n",
    "\n",
    "#vgg16\n",
    "#arg_model_xml=\"./tf_model/vgg16/FP16/all_layers.vgg16.xml\"\n",
    "#arg_model_bin=\"./tf_model/vgg16/FP16/all_layers.vgg16.bin\"\n",
    "\n",
    "#inception V3\n",
    "#arg_model_xml=\"./tf_model/iv3/FP16/inception_layers.iv3.xml\"\n",
    "#arg_model_bin=\"./tf_model/iv3/FP16/inception_layers.iv3.bin\"\n",
    "arg_device=\"MYRIAD\"\n",
    "arg_image_number = 50\n",
    "\n",
    "file_list = glob.glob(\"./test/*/*\")\n",
    "\n",
    "arg_cpu_extension=None\n",
    "\n",
    "arg_labels=\"./mn-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "plugin = IEPlugin(device=arg_device)\n",
    "net = IENetwork(model=arg_model_xml, weights=arg_model_bin)\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "exec_net = plugin.load(network=net, num_requests=1)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1, 1 + arg_image_number):\n",
    "    img_path = random.choice(file_list)\n",
    "    img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (w, h))\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = image.reshape((n, c, h, w))\n",
    "    image = preprocess_input(image)\n",
    "    res = exec_net.infer(inputs={input_blob: image}).get(out_blob)\n",
    "    top = res[0].argsort()[-1:][::-1]\n",
    "    pred_label = labels[top[0]]\n",
    "    print(\"image category:\", '{:25s}'.format(img_cat), \"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(\"inferred frames: \" + str(i) + \", average fps: \" + str(i/duration) +\"\\r\", end = '', flush = False)\n",
    "\n",
    "del exec_net\n",
    "del net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab2: inference sample code using async API (for iv3/mn/vgg16 model)\n",
    "### *arg_model_xml* : the model xml (generated from mo.py)\n",
    "### *arg_model_bin* : the model bin (generated from mo.py)\n",
    "### *arg_device* : the device to run inferences, can be one of CPU/GPU/MYRIAD\n",
    "### *arg_image_number* : total infer requests to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# async api demo\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# args\n",
    "arg_model_xml=\"./tf_model/mn/FP16/all_layers.mn.xml\"\n",
    "arg_model_bin=\"./tf_model/mn/FP16/all_layers.mn.bin\"\n",
    "arg_device=\"MYRIAD\"\n",
    "arg_image_number = 50\n",
    "\n",
    "file_list = glob.glob(\"./test/*/*\")\n",
    "\n",
    "arg_cpu_extension=None\n",
    "\n",
    "arg_labels=\"./mn-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "plugin = IEPlugin(device=arg_device)\n",
    "net = IENetwork(model=arg_model_xml, weights=arg_model_bin)\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "exec_net = plugin.load(network=net, num_requests=2)\n",
    "\n",
    "start_time = time.time()\n",
    "current_inference, next_inference = 0, 1\n",
    "current_img, next_img = None, None\n",
    "inferred_images = 0\n",
    "for i in range(0, arg_image_number):\n",
    "    img_path = random.choice(file_list)\n",
    "    img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, (w, h))\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = image.reshape((n, c, h, w))\n",
    "    image = preprocess_input(image)\n",
    "    exec_net.start_async(request_id=current_inference, inputs={input_blob: image})\n",
    "    current_img = img_cat\n",
    "    if exec_net.requests[next_inference].wait(-1) == 0:\n",
    "        inferred_images = inferred_images + 1\n",
    "        res = exec_net.requests[next_inference].outputs[out_blob]\n",
    "        top = res[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "        print(\"image category:\", '{:25s}'.format(next_img), \"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "    current_inference, next_inference = next_inference, current_inference\n",
    "    current_img, next_img = next_img, current_img\n",
    "# one more inference result left to check\n",
    "if exec_net.requests[next_inference].wait(-1) == 0:\n",
    "    inferred_images = inferred_images + 1\n",
    "    res = exec_net.requests[next_inference].outputs[out_blob]\n",
    "    top = res[0].argsort()[-1:][::-1]\n",
    "    pred_label = labels[top[0]]\n",
    "    print(\"image category:\", '{:25s}'.format(next_img), \"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(\"inferred frames:\", inferred_images ,\"average fps:\",inferred_images/duration)\n",
    "\n",
    "del exec_net\n",
    "del net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab3: inference sample code using async API, with multi-thread support  (for iv3/mn/vgg16 model)\n",
    "### *arg_model_xml* : the model xml (generated from mo.py)\n",
    "### *arg_model_bin* : the model bin (generated from mo.py)\n",
    "### *arg_device* : the device to run inferences, can be one of CPU/GPU/MYRIAD\n",
    "### *arg_image_number* : total infer requests to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# async api + multi-threads\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import multiprocessing\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# args\n",
    "arg_model_xml=\"./tf_model/mn/FP16/all_layers.mn.xml\"\n",
    "arg_model_bin=\"./tf_model/mn/FP16/all_layers.mn.bin\"\n",
    "arg_device=\"MYRIAD\"\n",
    "arg_image_number=50\n",
    "\n",
    "file_list = glob.glob(\"./test/*/*\")\n",
    "arg_cpu_extension=None\n",
    "\n",
    "arg_labels=\"./mn-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "def async_infer_worker(exec_net, image_queue, input_blob, out_blob):\n",
    "    global start_time\n",
    "\n",
    "    current_inference, next_inference = 0, 1\n",
    "    inferred_images = 0\n",
    "    while True:\n",
    "        image = image_queue.get()\n",
    "        if type(image) != np.ndarray:\n",
    "                break\n",
    "        exec_net.start_async(request_id=current_inference, inputs={input_blob: image})\n",
    "        if exec_net.requests[next_inference].wait(-1) == 0:\n",
    "            inferred_images = inferred_images + 1\n",
    "            res = exec_net.requests[next_inference].outputs[out_blob]\n",
    "            top = res[0].argsort()[-1:][::-1]\n",
    "            pred_label = labels[top[0]]\n",
    "            print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "        current_inference, next_inference = next_inference, current_inference\n",
    "    # one more inference result left to check\n",
    "    if exec_net.requests[next_inference].wait(-1) == 0:\n",
    "        inferred_images = inferred_images + 1\n",
    "        res = exec_net.requests[next_inference].outputs[out_blob]\n",
    "        top = res[0].argsort()[-1:][::-1]\n",
    "        pred_label = labels[top[0]]\n",
    "        print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "        \n",
    "    duration = time.time() - start_time\n",
    "    print(\"inferred frames:\", inferred_images ,\"average fps:\",inferred_images/duration)\n",
    "    \n",
    "def image_process_worker(image_queue, n, c, h, w):\n",
    "    for i in range(1, 1 + arg_image_number):\n",
    "        img_path = random.choice(file_list)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        image = preprocess_input(image)\n",
    "        image_queue.put(image)\n",
    "    image_queue.put(None)\n",
    "\n",
    "start_time = -1\n",
    "         \n",
    "def main():\n",
    "    global start_time\n",
    "\n",
    "    image_queue = queue.Queue(maxsize= 4)\n",
    "    \n",
    "    plugin = IEPlugin(device=arg_device)\n",
    "    net = IENetwork(model=arg_model_xml, weights=arg_model_bin)\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    exec_net = plugin.load(network=net, num_requests=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    preprocess_thread = None\n",
    "    preprocess_thread = threading.Thread(target=image_process_worker, args=(image_queue, n, c, h, w))\n",
    "    preprocess_thread.start()\n",
    "    \n",
    "    async_infer_worker(exec_net, image_queue, input_blob, out_blob)\n",
    "    \n",
    "    preprocess_thread.join()\n",
    "    \n",
    "    del exec_net\n",
    "    del net\n",
    "    del plugin\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab4: inference sample code using async API, with multi-thread and multi-requests support  (for iv3/mn/vgg16 model)\n",
    "### *arg_model_xml* : the model xml (generated from mo.py)\n",
    "### *arg_model_bin* : the model bin (generated from mo.py)\n",
    "### *arg_device* : the device to run inferences, can be one of CPU/GPU/MYRIAD\n",
    "### *arg_image_number* : total infer requests to run\n",
    "### *arg_request_number* : infer requests that run simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# async api + multi_threads + multi-requests\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import multiprocessing\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# args\n",
    "arg_model_xml=\"./tf_model/mn/FP16/all_layers.mn.xml\"\n",
    "arg_model_bin=\"./tf_model/mn/FP16/all_layers.mn.bin\"\n",
    "arg_device=\"MYRIAD\"\n",
    "arg_image_number = 50\n",
    "arg_request_number = 4\n",
    "\n",
    "file_list = glob.glob(\"./test/*/*\")\n",
    "arg_cpu_extension=None\n",
    "\n",
    "arg_labels=\"./mn-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "def async_infer_worker(exe_net, request_number, image_queue, input_blob, out_blob):\n",
    "    global start_time\n",
    "    \n",
    "    current_request_ids = range(request_number)\n",
    "    next_request_ids = range(request_number, request_number * 2)\n",
    "    done = False\n",
    "    last_batch = -1\n",
    "    inferred_images = 0\n",
    "    while True:\n",
    "        buffers = []\n",
    "        for i in range(request_number):\n",
    "            b = image_queue.get()\n",
    "            if type(b) != np.ndarray:\n",
    "                buffers.append(None)\n",
    "                done = True\n",
    "                break\n",
    "            else:\n",
    "                buffers.append(b)\n",
    "        for _request_id in current_request_ids:\n",
    "            if _request_id >=  request_number:\n",
    "                if type(buffers[_request_id - request_number]) == np.ndarray:\n",
    "                    exe_net.start_async(request_id=_request_id, inputs={input_blob: buffers[_request_id - request_number]})\n",
    "                else:\n",
    "                    #print(\"image at index \" + str(_request_id - request_number) + \" is none.\" )\n",
    "                    last_batch = _request_id - request_number\n",
    "                    break\n",
    "            else:\n",
    "                if type(buffers[_request_id]) == np.ndarray:\n",
    "                    exe_net.start_async(request_id=_request_id, inputs={input_blob: buffers[_request_id]})\n",
    "                else:\n",
    "                    #print(\"image at index \" + str(_request_id) + \" is none.\" )\n",
    "                    last_batch = _request_id\n",
    "                    break\n",
    "                    \n",
    "        for _request_id in next_request_ids:\n",
    "            if exe_net.requests[_request_id].wait(-1) == 0:\n",
    "                res = exe_net.requests[_request_id].outputs[out_blob]\n",
    "                inferred_images = inferred_images + 1\n",
    "                top = res[0].argsort()[-1:][::-1]\n",
    "                pred_label = labels[top[0]]\n",
    "                print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "\n",
    "        current_request_ids, next_request_ids = next_request_ids, current_request_ids\n",
    "        \n",
    "        for i in range(len(buffers)):\n",
    "            image_queue.task_done()\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # 'last_batch' more inference results remain to check\n",
    "    buffer_index = 0\n",
    "    for _request_id in next_request_ids:\n",
    "        if(buffer_index >= last_batch):\n",
    "            break\n",
    "        buffer_index = buffer_index + 1\n",
    "        if exe_net.requests[_request_id].wait(-1) == 0:\n",
    "            res = exe_net.requests[_request_id].outputs[out_blob]\n",
    "            inferred_images = inferred_images + 1\n",
    "            top = res[0].argsort()[-1:][::-1]\n",
    "            pred_label = labels[top[0]]\n",
    "            print( \"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "    duration = time.time() - start_time\n",
    "    print(\"inferred frames:\", inferred_images ,\"average fps:\",inferred_images/duration)\n",
    "\n",
    "def preprocess_worker(image_queue, n, c, h, w):\n",
    "    for i in range(1, 1 + arg_image_number):\n",
    "        img_path = random.choice(file_list)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        image = preprocess_input(image)\n",
    "        image_queue.put(image)\n",
    "    image_queue.put(None)\n",
    "\n",
    "start_time = -1\n",
    "           \n",
    "def main():\n",
    "    global start_time\n",
    "    \n",
    "    image_queue = queue.Queue(maxsize= arg_request_number*3)\n",
    "\n",
    "    plugin = IEPlugin(device=arg_device)\n",
    "    net = IENetwork(model=arg_model_xml, weights=arg_model_bin)\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    exec_net = plugin.load(network=net, num_requests=arg_request_number*2)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    preprocess_thread = None\n",
    "    preprocess_thread = threading.Thread(target=preprocess_worker, args=(image_queue, n, c, h, w))\n",
    "    preprocess_thread.start()\n",
    "    \n",
    "    async_infer_worker(exec_net, arg_request_number, image_queue, input_blob, out_blob)\n",
    "\n",
    "    preprocess_thread.join()\n",
    "    \n",
    "    del exec_net\n",
    "    del net\n",
    "    del plugin\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab5: inference sample code using async API, with multi-thread, multi-requests and multi-ncs support  (for iv3/mn/vgg16 model)\n",
    "### *arg_model_xml* : the model xml (generated from mo.py)\n",
    "### *arg_model_bin* : the model bin (generated from mo.py)\n",
    "### *arg_device* : the device to run inferences, can be one of CPU/GPU/MYRIAD\n",
    "### *arg_image_number* : total infer requests to run\n",
    "### *arg_request_number* : infer requests that run simultaneously\n",
    "### *arg_ncs_number* :  ncs number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# async api + multi-threads + multi-requests + multi-ncs\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import multiprocessing\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# args\n",
    "arg_model_xml=\"./tf_model/mn/FP16/all_layers.mn.xml\"\n",
    "arg_model_bin=\"./tf_model/mn/FP16/all_layers.mn.bin\"\n",
    "arg_device=\"MYRIAD\"\n",
    "arg_image_number = 100\n",
    "arg_request_number = 4\n",
    "arg_ncs_number = 2\n",
    "\n",
    "file_list = glob.glob(\"./test/*/*\")\n",
    "arg_cpu_extension=None\n",
    "arg_labels=\"./mn-labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "\n",
    "inferred_images = 0\n",
    "def async_infer_worker(exe_net, request_number, image_queue, input_blob, out_blob):\n",
    "    global start_time\n",
    "    global inferred_images\n",
    "    global arg_image_number\n",
    "    \n",
    "    current_request_ids = range(request_number)\n",
    "    next_request_ids = range(request_number, request_number * 2)\n",
    "    done = False\n",
    "    last_batch = -1\n",
    "    while True:\n",
    "        buffers = []\n",
    "        for i in range(request_number):\n",
    "            b = image_queue.get()\n",
    "            if type(b) != np.ndarray:\n",
    "                buffers.append(None)\n",
    "                done = True\n",
    "                break\n",
    "            else:\n",
    "                buffers.append(b)\n",
    "        for _request_id in current_request_ids:\n",
    "            if _request_id >=  request_number:\n",
    "                if type(buffers[_request_id - request_number]) == np.ndarray:\n",
    "                    exe_net.start_async(request_id=_request_id, inputs={input_blob: buffers[_request_id - request_number]})\n",
    "                else:\n",
    "                    #print(\"image at index \" + str(_request_id - request_number) + \" is none.\" )\n",
    "                    last_batch = _request_id - request_number\n",
    "                    break\n",
    "            else:\n",
    "                if type(buffers[_request_id]) == np.ndarray:\n",
    "                    exe_net.start_async(request_id=_request_id, inputs={input_blob: buffers[_request_id]})\n",
    "                else:\n",
    "                    #print(\"image at index \" + str(_request_id) + \" is none.\" )\n",
    "                    last_batch = _request_id\n",
    "                    break\n",
    "                    \n",
    "        for _request_id in next_request_ids:\n",
    "            if exe_net.requests[_request_id].wait(-1) == 0:\n",
    "                res = exe_net.requests[_request_id].outputs[out_blob]\n",
    "                inferred_images = inferred_images + 1\n",
    "                top = res[0].argsort()[-1:][::-1]\n",
    "                pred_label = labels[top[0]]\n",
    "                print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "\n",
    "        current_request_ids, next_request_ids = next_request_ids, current_request_ids\n",
    "        \n",
    "        for i in range(len(buffers)):\n",
    "            image_queue.task_done()\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # 'last_batch' more inference results remain to check\n",
    "    buffer_index = 0\n",
    "    for _request_id in next_request_ids:\n",
    "        if(buffer_index >= last_batch):\n",
    "            break\n",
    "        buffer_index = buffer_index + 1\n",
    "        if exe_net.requests[_request_id].wait(-1) == 0:\n",
    "            res = exe_net.requests[_request_id].outputs[out_blob]\n",
    "            inferred_images = inferred_images + 1\n",
    "            top = res[0].argsort()[-1:][::-1]\n",
    "            pred_label = labels[top[0]]\n",
    "            print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "    if inferred_images == arg_image_number:\n",
    "        duration = time.time() - start_time\n",
    "        print(\"inferred frames:\", inferred_images ,\"average fps:\",inferred_images/duration)\n",
    "\n",
    "def preprocess_worker(image_queue, ncs_number, n, c, h, w):\n",
    "    global arg_image_number\n",
    "    \n",
    "    for i in range(1, 1 + arg_image_number):\n",
    "        img_path = random.choice(file_list)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        image = preprocess_input(image)\n",
    "        image_queue.put(image)\n",
    "    for i in range(ncs_number):\n",
    "        image_queue.put(None)\n",
    "\n",
    "start_time = -1\n",
    "\n",
    "def main():\n",
    "    global start_time\n",
    "    global arg_ncs_number\n",
    "    \n",
    "    image_queue = queue.Queue(maxsize= arg_ncs_number*arg_request_number*4)\n",
    "\n",
    "    plugin = IEPlugin(device=arg_device)\n",
    "    net = IENetwork(model=arg_model_xml, weights=arg_model_bin)\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    \n",
    "    exec_nets = []\n",
    "    for i in range(arg_ncs_number):\n",
    "        exec_net = plugin.load(network=net, num_requests=arg_request_number*2)\n",
    "        exec_nets.append(exec_net)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    preprocess_thread = threading.Thread(target=preprocess_worker, args=(image_queue, arg_ncs_number, n, c, h, w), daemon=True)\n",
    "    preprocess_thread.start()\n",
    "    \n",
    "    infer_threads = [] \n",
    "    for f in range(arg_ncs_number):\n",
    "        _worker = threading.Thread(target=async_infer_worker, args=(exec_nets[f], arg_request_number, image_queue, input_blob, out_blob))\n",
    "        _worker.start()\n",
    "        infer_threads.append(_worker)\n",
    "\n",
    "    preprocess_thread.join()\n",
    "    for _inf_thread in infer_threads:\n",
    "        _inf_thread.join()\n",
    "    \n",
    "    for exec_net in exec_nets:\n",
    "        del exec_net\n",
    "    del net\n",
    "    del plugin\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Optional - Lab6: inference sample code using async API, with multi-process, multi-requests and multi-ncs support  (for iv3/mn/vgg16 model)\n",
    "### *arg_model_xml* : the model xml (generated from mo.py)\n",
    "### *arg_model_bin* : the model bin (generated from mo.py)\n",
    "### *arg_device* : the device to run inferences, can be one of CPU/GPU/MYRIAD\n",
    "### *arg_image_number* : total infer requests to run\n",
    "### *arg_request_number* : infer requests that run simultaneously\n",
    "### *arg_ncs_number* : ncs number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# async api + multi-processes + multi-requests + multi-ncs\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "import multiprocessing\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# args\n",
    "arg_model_xml=\"./tf_model/mn/FP16/all_layers.mn.xml\"\n",
    "arg_model_bin=\"./tf_model/mn/FP16/all_layers.mn.bin\"\n",
    "arg_device=\"MYRIAD\"\n",
    "arg_labels=\"./mn-labels.txt\"\n",
    "arg_image_number = 100\n",
    "arg_request_number = 4\n",
    "arg_ncs_number = 2\n",
    "\n",
    "file_list = glob.glob(\"./test/*/*\")\n",
    "arg_cpu_extension=None\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "\n",
    "inferred_images = 0\n",
    "def async_infer_worker(exe_net, request_number, image_queue, input_blob, out_blob):\n",
    "    global start_time\n",
    "    global inferred_images\n",
    "    global arg_image_number\n",
    "    \n",
    "    current_request_ids = range(request_number)\n",
    "    next_request_ids = range(request_number, request_number * 2)\n",
    "    done = False\n",
    "    last_batch = -1\n",
    "    while True:\n",
    "        buffers = []\n",
    "        for i in range(request_number):\n",
    "            b = image_queue.get()\n",
    "            if type(b) != np.ndarray:\n",
    "                buffers.append(None)\n",
    "                done = True\n",
    "                break\n",
    "            else:\n",
    "                buffers.append(b)\n",
    "        for _request_id in current_request_ids:\n",
    "            if _request_id >=  request_number:\n",
    "                if type(buffers[_request_id - request_number]) == np.ndarray:\n",
    "                    exe_net.start_async(request_id=_request_id, inputs={input_blob: buffers[_request_id - request_number]})\n",
    "                else:\n",
    "                    #print(\"image at index \" + str(_request_id - request_number) + \" is none.\" )\n",
    "                    last_batch = _request_id - request_number\n",
    "                    break\n",
    "            else:\n",
    "                if type(buffers[_request_id]) == np.ndarray:\n",
    "                    exe_net.start_async(request_id=_request_id, inputs={input_blob: buffers[_request_id]})\n",
    "                else:\n",
    "                    #print(\"image at index \" + str(_request_id) + \" is none.\" )\n",
    "                    last_batch = _request_id\n",
    "                    break\n",
    "                    \n",
    "        for _request_id in next_request_ids:\n",
    "            if exe_net.requests[_request_id].wait(-1) == 0:\n",
    "                res = exe_net.requests[_request_id].outputs[out_blob]\n",
    "                inferred_images = inferred_images + 1\n",
    "                top = res[0].argsort()[-1:][::-1]\n",
    "                pred_label = labels[top[0]]\n",
    "                print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "\n",
    "        current_request_ids, next_request_ids = next_request_ids, current_request_ids\n",
    "        \n",
    "        #for i in range(len(buffers)):\n",
    "        #    image_queue.task_done()\n",
    "            \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # 'last_batch' more inference results remain to check\n",
    "    buffer_index = 0\n",
    "    for _request_id in next_request_ids:\n",
    "        if(buffer_index >= last_batch):\n",
    "            break\n",
    "        buffer_index = buffer_index + 1\n",
    "        if exe_net.requests[_request_id].wait(-1) == 0:\n",
    "            res = exe_net.requests[_request_id].outputs[out_blob]\n",
    "            inferred_images = inferred_images + 1\n",
    "            top = res[0].argsort()[-1:][::-1]\n",
    "            pred_label = labels[top[0]]\n",
    "            print(\"predict result:\", '{:25s}'.format(pred_label), \"confidence:\", res[0][top[0]])\n",
    "    if inferred_images == arg_image_number:\n",
    "        duration = time.time() - start_time\n",
    "        print(\"inferred frames:\", inferred_images ,\"average fps:\",inferred_images/duration)\n",
    "\n",
    "def preprocess_worker(image_queue, ncs_number, n, c, h, w):\n",
    "    \n",
    "    for i in range(1, 1 + arg_image_number):\n",
    "        img_path = random.choice(file_list)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.reshape((n, c, h, w))\n",
    "        image = preprocess_input(image)\n",
    "        image_queue.put(image)\n",
    "    for i in range(ncs_number):\n",
    "        image_queue.put(None)\n",
    "\n",
    "start_time = -1\n",
    "\n",
    "def main():\n",
    "    global start_time\n",
    "    global arg_ncs_number\n",
    "    \n",
    "    image_queue = multiprocessing.Queue(maxsize= arg_ncs_number*arg_request_number*4)\n",
    "\n",
    "    plugin = IEPlugin(device=arg_device)\n",
    "    net = IENetwork(model=arg_model_xml, weights=arg_model_bin)\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "    n, c, h, w = net.inputs[input_blob].shape\n",
    "    \n",
    "    exec_nets = []\n",
    "    for i in range(arg_ncs_number):\n",
    "        exec_net = plugin.load(network=net, num_requests=arg_request_number*2)\n",
    "        exec_nets.append(exec_net)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    preprocess_process = multiprocessing.Process(target=preprocess_worker, args=(image_queue, arg_ncs_number, n, c, h, w), daemon=True)\n",
    "    preprocess_process.start()\n",
    "    \n",
    "    infer_threads = [] \n",
    "    for f in range(arg_ncs_number):\n",
    "        _worker = threading.Thread(target=async_infer_worker, args=(exec_nets[f], arg_request_number, image_queue, input_blob, out_blob))\n",
    "        _worker.start()\n",
    "        infer_threads.append(_worker)\n",
    "\n",
    "    preprocess_process.join()\n",
    "    for _inf_thread in infer_threads:\n",
    "        _inf_thread.join()\n",
    "    \n",
    "    for exec_net in exec_nets:\n",
    "        del exec_net\n",
    "    del net\n",
    "    del plugin\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_training",
   "language": "python",
   "name": "tf_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
